{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Char-nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjohnst5/Char-nn/blob/master/Char_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Description:\n",
        "An implementation of the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original. For more reading see [here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "## Results\n",
        "* Wiring up a basic sequence-to-sequence computation graph\n",
        "* Implementing a GRU cell.\n",
        "\n",
        "\n",
        "An example of my final samples are shown below after 150 passes through the Lord of the Rings text dataset.\n",
        "\n",
        "<code>\n",
        "eide and the cece the eviled understade and Shire. \n",
        "Them. And the rider his allove. \n",
        "It he hape\n",
        " eer was need to of more blown to still new rithed to have collong to not the our to the \n",
        "mucker abou\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Data loading and high level training\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l7bdZWxvJrsx",
        "outputId": "d4b84915-2cb0-4dca-ec93-6551ed7b9a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-18 18:12:16--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 52.45.119.166, 3.214.17.10, 52.2.48.133, ...\n",
            "Connecting to piazza.com (piazza.com)|52.45.119.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2019-10-18 18:12:17--  https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)... 13.249.94.147, 13.249.94.143, 13.249.94.174, ...\n",
            "Connecting to d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)|13.249.94.147|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "\r./text_files.tar.gz   0%[                    ]       0  --.-KB/s               \r./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-10-18 18:12:17 (25.2 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "file_len = 2579888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxBeKeNjJ0NQ",
        "outputId": "c40135f3-f05a-4f7e-8034-e907672f3545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "swer, but he took the other's eye and held it, \n",
            "and for a moment they strove thus; but soon, though Aragorn did not stir nor \n",
            "move hand to weapon, the other quailed and gave back as if menaced with a \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "On0_WitWJ99e",
        "outputId": "3dee0f93-410e-47df-c015-e4cebe7118f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Creating a GRU cell \n",
        "\n",
        "---\n",
        "\n",
        "The cell I used previously was a pre-defined Pytorch layer. I will now write a  GRU class using the same parameters as the built-in Pytorch class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aavAv50ZKQ-F",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "    \n",
        "    self.W_ir = nn.Linear(input_size, hidden_size)\n",
        "    self.W_hr = nn.Linear(hidden_size, hidden_size)\n",
        "    \n",
        "    self.W_iz = nn.Linear(input_size, hidden_size)\n",
        "    self.W_hz = nn.Linear(hidden_size, hidden_size)\n",
        "    \n",
        "    self.W_in = nn.Linear(input_size, hidden_size)\n",
        "    self.W_hn = nn.Linear(hidden_size, hidden_size)\n",
        "      \n",
        "  def forward(self, inputs, hidden):\n",
        "    # hidden : (n_layers, batch, hidden_size)\n",
        "    \n",
        "    # Each layer does the following:\n",
        "    # r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
        "    # z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
        "    # n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
        "    # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "    # Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
        "    r_t = self.sigmoid(self.W_ir(inputs) + self.W_hr(hidden))\n",
        "    z_t = self.sigmoid(self.W_iz(inputs) + self.W_hz(hidden))\n",
        "    n_t = self.tanh(self.W_in(inputs) + r_t * (self.W_hn(hidden)))\n",
        "    hiddens = (1 - z_t) * n_t + z_t * hidden\n",
        "    \n",
        "    return n_t, hiddens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Building a sequence to sequence model\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d6tNdEnzWj5F",
        "colab": {}
      },
      "source": [
        "#linear layer takes hidden size and shrinks it to vocab size\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size # num characters\n",
        "    self.hidden_size = hidden_size # 200\n",
        "    self.output_size = output_size # num characters\n",
        "    self.n_layers = n_layers # 3\n",
        "  \n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = GRU(hidden_size, hidden_size, n_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    output = self.embedding(input_char).view(1, 1, -1)\n",
        "    \n",
        "    output = F.relu(output)\n",
        "    \n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    \n",
        "    output = self.out(output[0])\n",
        "    \n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrhXghEPKD-5",
        "colab": {}
      },
      "source": [
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ALC3Pf8Kbsi",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "def train(decoder, decoder_optimizer, criterion, inp, target):\n",
        "  ## initialize hidden layers, set up gradient and loss \n",
        "  decoder_optimizer.zero_grad()\n",
        "  hidden = decoder.init_hidden()\n",
        "  loss = 0\n",
        "  \n",
        "  for x, y in zip(inp, target):\n",
        "    y_hat, hidden = decoder(x, hidden)\n",
        "    \n",
        "    loss += criterion(y_hat, y.unsqueeze(0))\n",
        "   \n",
        "  loss.backward()\n",
        "  decoder_optimizer.step()\n",
        "  return loss.item() / target.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Sampling text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "This method takes as input a decoder and creates a string of the given length.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B-bp-OZ1KjNh",
        "colab": {}
      },
      "source": [
        "def evaluate(decoder, prime_str='A', predict_len=100, temperature=0.8):\n",
        "  ## initialize hidden variable, initialize other useful variables \n",
        "    # your code here\n",
        "  ## /\n",
        "  prime_str = char_tensor(prime_str)\n",
        "  hidden = decoder.init_hidden()\n",
        "  output_str = \"\"\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    while len(output_str) < predict_len:\n",
        "      for char in prime_str:\n",
        "        prediction, hidden = decoder(char, hidden)\n",
        "        \n",
        "        prediction = torch.exp(prediction / temperature)\n",
        "        \n",
        "        sample_index = torch.multinomial(prediction, 1)\n",
        "        \n",
        "        output_str += all_characters[sample_index]\n",
        "      \n",
        "      prime_str = sample_index\n",
        "  \n",
        "  return output_str"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Running it and generating some text!\n",
        "\n",
        "---\n",
        "Now time to run the model. This will train the model outputting sample strings along the way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xKfozqw-6eqb",
        "outputId": "781991d7-8c76-4e1b-cf87-6bf11df6d95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import time\n",
        "import gc\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "\n",
        "def print_strings(strings):\n",
        "  for i in range(len(strings)):\n",
        "    print(\"\\n\\t--------- output string \", i+1, \" -----------\\n\", strings[i])\n",
        "\n",
        "\n",
        "def run():\n",
        "  try:\n",
        "    gc.collect()\n",
        "    \n",
        "    n_epochs = 2000\n",
        "    print_every = 130\n",
        "    plot_every = 200\n",
        "    hidden_size = 200\n",
        "    n_layers = 1\n",
        "    lr = 0.001\n",
        "\n",
        "    decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    start = time.time()\n",
        "    all_losses = []\n",
        "    output_strings = []\n",
        "    loss_avg = 0\n",
        "\n",
        "    loop = tqdm(total=n_epochs, position=0, leave=False)\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "      loss_ = train(decoder, decoder_optimizer, criterion, *random_training_set())       \n",
        "      loss_avg += loss_\n",
        "\n",
        "      if epoch % print_every == 0:\n",
        "          output_strings.append(evaluate(decoder, 'Wh', 100))\n",
        "\n",
        "      if epoch % plot_every == 0:\n",
        "          all_losses.append(loss_avg / plot_every)\n",
        "          loss_avg = 0\n",
        "\n",
        "      loop.set_description('loss:{:.4f}'.format(loss_))\n",
        "      loop.update(1)\n",
        "\n",
        "    return output_strings, all_losses, decoder\n",
        "\n",
        "  except:\n",
        "      __ITB__()\n",
        "\n",
        "output_strings, all_losses, decoder = run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:1.7562: 100%|██████████| 2000/2000 [09:02<00:00,  3.66it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2EFfOvGb2No",
        "colab_type": "code",
        "outputId": "122c49db-37bc-41e2-9eee-b919c0dd8f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_strings(output_strings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\t--------- output string  1  -----------\n",
            " eed and kees Ipat \n",
            "re sthist deay gepaprher thaind rooly nore ad \n",
            "aid heeg heed thit chid uro had he\n",
            "\n",
            "\t--------- output string  2  -----------\n",
            "  alg stound ar of the wisch wite ting was wared siesteri thes the sewith cocli!, stor theven ard \n",
            "'n\n",
            "\n",
            "\t--------- output string  3  -----------\n",
            "  our speat pleds it up frentherst that in to now It surep na \n",
            "old the sseade lodsthed deard and the \n",
            "\n",
            "\t--------- output string  4  -----------\n",
            " eed liges they are mame had ouck with that they fille gow Polver \n",
            "pilk ta had 'med Gavary sund mill \n",
            "\n",
            "\t--------- output string  5  -----------\n",
            "  en the shalls freat and fured to to houg. I wat rompoon the done it we ball, of that were stree fir\n",
            "\n",
            "\t--------- output string  6  -----------\n",
            "  en Jo dere, and land ley for hears for \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "'Wat hought love silly high. But to \n",
            "lowe his were the\n",
            "\n",
            "\t--------- output string  7  -----------\n",
            " ee limany his come sider, and caney; by the Sing to we \n",
            "ince with \n",
            "with the free!' said \n",
            "he arrodo t\n",
            "\n",
            "\t--------- output string  8  -----------\n",
            " eid, of was lond and great goust of ollorded in the lend be there for the wadder did not in wilk cha\n",
            "\n",
            "\t--------- output string  9  -----------\n",
            " eo the mower he smane slippents of the \n",
            "lead his pottering frike were in himod fill, affel it with a\n",
            "\n",
            "\t--------- output string  10  -----------\n",
            " eing that wo foint in the wandel and soot. I coust in though the slide toward of the fire has sound \n",
            "\n",
            "\t--------- output string  11  -----------\n",
            " eide and the cece the eviled understade and Shire. \n",
            "\n",
            "'Them. And the rider his allove.' \n",
            "\n",
            "'It he hape\n",
            "\n",
            "\t--------- output string  12  -----------\n",
            " eer was need to of more blown to still new rithed to have collong to not the our to the \n",
            "mucker abou\n",
            "\n",
            "\t--------- output string  13  -----------\n",
            " ee weress, the Dors; and \n",
            "orochorn \n",
            "bear great \n",
            "or been the grown of the well ever of the Merry not \n",
            "\n",
            "\t--------- output string  14  -----------\n",
            " aer ring at the Creat and a follong. We weat norsell. He light in it were last pround in the fath. T\n",
            "\n",
            "\t--------- output string  15  -----------\n",
            " eer glack fare of great all the \n",
            "truen the roch through thram his the Elving like all keeming. I'd b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ee0so6aKJ5L8",
        "outputId": "5b815bc4-56cc-46a7-860d-0f3a0a82a4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(decoder, start_strings[start], 200), '\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Th\n",
            "loen reat be and do \n",
            "diswering bread heart nawel, \n",
            "he were, and the toads now, and he heave he sleat he say hobbits of the tiner the \n",
            "groms head all wisthing, you said and they holder and their pather \n",
            "\n",
            " wh\n",
            "teat all coupting of mengn and dalk \n",
            "the ridden of Ores for he sungen to to ace one for shadows felt and were in the what the was not when arry that I walls seen goting of the choom anaver may \n",
            "\n",
            "chang \n",
            "\n",
            " ca\n",
            "aon ring trurd. Then is a was inter the nor the Roantine rooming \n",
            "of enen and an the slowed not them thought they find them,' said Gandalf of the farbbight in the Earths begone of ambing his feery of  \n",
            "\n",
            " wh\n",
            "aaile here the \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fromm tuer fating of the Itried and rest I lat me \n",
            "cound upon a land him side now and that reas and \n",
            "ane and \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "and been that they hom's be seep and you frim and think and  \n",
            "\n",
            " Th\n",
            "shings and be not hell in the that less uppeary water of an \n",
            "manes lants that id no beed amponike then we dee than of \n",
            "comporouned we find weRtentel before fall, and she lay hand of the reast beaving  \n",
            "\n",
            " G\n",
            "\n",
            "andand was \n",
            "sprend in the runger for Pippor spefter the waster hords was almon the \n",
            "feet he sood, and the cants. 'It swind trought feen to doar we looked ofter for a been \n",
            "ach to lead to mush to hall \n",
            "\n",
            " he\n",
            "he will in \n",
            "the strings should the mark to mreming a shouse- and be \n",
            "much arubled to and berowains. \n",
            "\n",
            "He \n",
            "went of Mordres, and the cauned so their lit lioked and the ring, grown about goward. I' not h \n",
            "\n",
            " wh\n",
            "aeith did no before on the upant of had and boried to not one as the panted, and the \n",
            "whong. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Halt beting there \n",
            "Sam on the hassed all all so reaffer inter miven and the bead befind on a shadow t \n",
            "\n",
            " ca\n",
            "tonst our down was. \n",
            "\n",
            "'You's looked and sout ago,' he hecke seemed with the \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bean the \n",
            "Cambing bent, I all waused harast becost old the Sardo9 and flower who began, she fanging the sid \n",
            "\n",
            " ra\n",
            "tuming the shumble, San fele until befire weall and stild, the not was ancented to \n",
            "me up't get \n",
            "the \n",
            "Crawarus was begowarf of the \n",
            "and in the doand of Sout he pararied gown about of the dound \n",
            "out up \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Generating output on a different dataset\n",
        "\n",
        "---\n",
        "I will now generate output from a Shakespeare dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OZUHyNHJKUu",
        "colab_type": "code",
        "outputId": "6713e2c7-0370-428a-ba69-732605289406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "file = unidecode.unidecode(open(path_to_file).read())\n",
        "file_len = len(file)\n",
        "all_characters = sorted(set(file))\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "output_strings2, all_losses2, _ = run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss:1.5133: 100%|██████████| 2000/2000 [09:17<00:00,  3.63it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv0lSqxjQuqV",
        "colab_type": "code",
        "outputId": "2f1ab671-0a7c-4ddc-c448-f4516a443487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_strings(output_strings2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\t--------- output string  1  -----------\n",
            " ee thes mand ay dhelat keo ou ound the hive, er, o cithoon whteabe,\n",
            "Ak I hour bed shit wegse tonde r\n",
            "\n",
            "\t--------- output string  2  -----------\n",
            " Iith ave tr'ull mistiand un mede\n",
            "Hard of and ind irs ack ond tnouce thar fersty wonds,\n",
            "Whe the ince \n",
            "\n",
            "\t--------- output string  3  -----------\n",
            " ie, wrist him, mares rovesis?\n",
            "\n",
            "PERINGRONTIE:\n",
            "No to cyelisktinall pore! grese soust Ifows fare, herd,\n",
            "\n",
            "\t--------- output string  4  -----------\n",
            " hor the siir aid of and for,\n",
            "And sherm nat hit come; indon ence id cood houch my consime of hightet \n",
            "\n",
            "\t--------- output string  5  -----------\n",
            " eich will steald ruseds onsame, of them,\n",
            "Incousefrerss with that your theminr of insush a moness upp\n",
            "\n",
            "\t--------- output string  6  -----------\n",
            " iat she dost's live's hims.\n",
            "\n",
            "POMKENTES:\n",
            "Araid A farines own to the slime,\n",
            "A so home, then his peath \n",
            "\n",
            "\t--------- output string  7  -----------\n",
            " eibe sourth as mestard,\n",
            "Whace not so light, to heaked a puse.\n",
            "\n",
            "PRING:\n",
            "I me be menter sue thou son bo\n",
            "\n",
            "\t--------- output string  8  -----------\n",
            " eangay, frow dike then and:\n",
            "I stuck hard I to tone of hing me the clows.\n",
            "The past you shall opents; \n",
            "\n",
            "\t--------- output string  9  -----------\n",
            " \n",
            "is, Whan of sto miness,\n",
            "Bow, net on the mine is preiet. I and buss and are the fan three in,\n",
            "Betere\n",
            "\n",
            "\t--------- output string  10  -----------\n",
            " iing you riars\n",
            "My destakes your would sirn here make at more to times of he laded insty\n",
            "The bear as \n",
            "\n",
            "\t--------- output string  11  -----------\n",
            " eer, Vifert'd her, -for agmand?\n",
            "What her re: the seech larce to more\n",
            "that stial me is no the duest h\n",
            "\n",
            "\t--------- output string  12  -----------\n",
            " eat in the suchers and enit her speable where whorter.\n",
            "\n",
            "SAPPUTES:\n",
            "If shall who wat we stan with funs\n",
            "\n",
            "\t--------- output string  13  -----------\n",
            " aand than not then the well\n",
            "Have thee but with sir, whin the pooth with stang my prey\n",
            "To dish dutter\n",
            "\n",
            "\t--------- output string  14  -----------\n",
            " Aat of three to a with dose,\n",
            "Sir, in thee thy do more is waster whis.\n",
            "\n",
            "ABAUS:\n",
            "Now, in a geed of thee\n",
            "\n",
            "\t--------- output string  15  -----------\n",
            " hing bodrent to other,\n",
            "Thou how kil, shall our senter from the die\n",
            "How not the brother cound my from\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ41Z_FsXFF5",
        "colab_type": "text"
      },
      "source": [
        "**Performance evaluation**\n",
        "\n",
        "I'd say my model did pretty well. It was able to change styles of writing depending on the dataset and actually outputted english words."
      ]
    }
  ]
}